{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83f59d1",
   "metadata": {},
   "source": [
    "# 5-Fold CV Baseline (Unplanned Hospitalization 6mo)\n",
    "\n",
    "- Dataset: `anhui_ltcf_dataset.xlsx`\n",
    "- Target: `unplanned_hospitalization_6mo`\n",
    "- Features: **all columns except target** (optionally drops ID columns like `resident_id` if present)\n",
    "- Models (5): Logistic Regression, SVM (RBF), Decision Tree, Random Forest, Gradient Boosting\n",
    "- Metrics: Accuracy, Precision, Recall, F1, ROC-AUC (mean ± std across 5 folds)\n",
    "- Threshold for class prediction: **0.5** (no DCA / no threshold tuning)\n",
    "\n",
    "> If your Excel file is not in the same folder as this notebook, change `DATA_PATH` below.\n",
    "\n",
    "\n",
    "**Note:** This notebook is an illustrative baseline workflow. It avoids displaying row-level sample records. Please consult the codebook for authoritative variable definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c71a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load data (dataset + codebook)\n",
    "DATA_PATH = \"anhui_ltcf_dataset.xlsx\"               # dataset file in the repository package\n",
    "CODEBOOK_PATH = \"anhui_ltcf_routine_codebook.xlsx\"  # codebook file in the repository package\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "codebook = pd.read_excel(CODEBOOK_PATH)\n",
    "\n",
    "print(\"Dataset shape (rows, cols):\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "TARGET_COL = \"unplanned_hospitalization_6mo\"\n",
    "assert TARGET_COL in df.columns, f\"Target column not found: {TARGET_COL}\"\n",
    "\n",
    "# Separate y and X\n",
    "y = df[TARGET_COL].astype(int).copy()\n",
    "X = df.drop(columns=[TARGET_COL]).copy()\n",
    "\n",
    "# Drop identifier columns based on the codebook (prevents leakage)\n",
    "id_cols = codebook.loc[codebook[\"Type\"].astype(str).str.lower().eq(\"identifier\"), \"Dataset column\"].tolist()\n",
    "id_cols = [c for c in id_cols if c in X.columns]\n",
    "if id_cols:\n",
    "    X = X.drop(columns=id_cols)\n",
    "    print(\"Dropped identifier columns:\", id_cols)\n",
    "\n",
    "# (Recommended) Also drop facility_id if present, even if not flagged (safety check)\n",
    "if \"facility_id\" in X.columns:\n",
    "    X = X.drop(columns=[\"facility_id\"])\n",
    "    print(\"Dropped facility_id (identifier)\")\n",
    "\n",
    "print(\"X shape (after drops):\", X.shape)\n",
    "print(\"Outcome balance (0/1):\")\n",
    "print(y.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc45c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing: codebook-driven numeric/categorical pipelines\n",
    "# Use the codebook to determine which features are continuous vs categorical/ordinal.\n",
    "# In this dataset, most variables are integer-coded categorical/ordinal; only a small subset are continuous.\n",
    "\n",
    "codebook_types = codebook.set_index(\"Dataset column\")[\"Type\"].astype(str)\n",
    "\n",
    "# Columns present in X (after dropping identifiers)\n",
    "cols_in_X = [c for c in X.columns if c in codebook_types.index]\n",
    "\n",
    "numeric_features = [c for c in cols_in_X if codebook_types[c].lower().strip() == \"numeric (continuous)\"]\n",
    "categorical_features = [c for c in cols_in_X if codebook_types[c].lower().strip().startswith(\"categorical\")]\n",
    "\n",
    "# Any remaining columns (unexpected types) will be treated as categorical to avoid scaling codes\n",
    "other_features = [c for c in cols_in_X if c not in numeric_features and c not in categorical_features]\n",
    "categorical_features = categorical_features + other_features\n",
    "\n",
    "print(f\"Numeric continuous features: {len(numeric_features)} -> {numeric_features}\")\n",
    "print(f\"Categorical/ordinal features: {len(categorical_features)}\")\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define 5 models (baseline hyperparams; no grid search)\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=2000, solver=\"lbfgs\", random_state=RANDOM_STATE),\n",
    "    \"SVM(RBF)\": SVC(probability=True, kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=RANDOM_STATE),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=400, random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ),\n",
    "    \"GBDT\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    name: Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", mdl)])\n",
    "    for name, mdl in models.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5-fold Stratified CV evaluation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "summary_rows = []\n",
    "oof_pred_proba = {name: np.full(shape=(len(y),), fill_value=np.nan, dtype=float) for name in pipelines.keys()}\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    fold_metrics = []\n",
    "    for fold, (tr_idx, te_idx) in enumerate(cv.split(X, y), start=1):\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        # Probability for ROC-AUC\n",
    "        proba = pipe.predict_proba(X_te)[:, 1]\n",
    "        oof_pred_proba[name][te_idx] = proba\n",
    "\n",
    "        # Class prediction with fixed 0.5 threshold\n",
    "        y_pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "        m = {\n",
    "            \"fold\": fold,\n",
    "            \"accuracy\": accuracy_score(y_te, y_pred),\n",
    "            \"precision\": precision_score(y_te, y_pred, zero_division=0),\n",
    "            \"recall\": recall_score(y_te, y_pred, zero_division=0),\n",
    "            \"f1\": f1_score(y_te, y_pred, zero_division=0),\n",
    "            \"roc_auc\": roc_auc_score(y_te, proba),\n",
    "        }\n",
    "        fold_metrics.append(m)\n",
    "\n",
    "    fold_df = pd.DataFrame(fold_metrics)\n",
    "    row = {\n",
    "        \"model\": name,\n",
    "        \"acc_mean\": fold_df[\"accuracy\"].mean(), \"acc_std\": fold_df[\"accuracy\"].std(ddof=1),\n",
    "        \"prec_mean\": fold_df[\"precision\"].mean(), \"prec_std\": fold_df[\"precision\"].std(ddof=1),\n",
    "        \"rec_mean\": fold_df[\"recall\"].mean(), \"rec_std\": fold_df[\"recall\"].std(ddof=1),\n",
    "        \"f1_mean\": fold_df[\"f1\"].mean(), \"f1_std\": fold_df[\"f1\"].std(ddof=1),\n",
    "        \"auc_mean\": fold_df[\"roc_auc\"].mean(), \"auc_std\": fold_df[\"roc_auc\"].std(ddof=1),\n",
    "    }\n",
    "    summary_rows.append(row)\n",
    "\n",
    "summary = pd.DataFrame(summary_rows).sort_values(\"auc_mean\", ascending=False)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca1d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pretty print mean ± std\n",
    "def fmt(m, s):\n",
    "    return f\"{m:.3f} ± {s:.3f}\"\n",
    "\n",
    "pretty = summary.copy()\n",
    "pretty[\"Accuracy\"] = [fmt(m, s) for m, s in zip(pretty.acc_mean, pretty.acc_std)]\n",
    "pretty[\"Precision\"] = [fmt(m, s) for m, s in zip(pretty.prec_mean, pretty.prec_std)]\n",
    "pretty[\"Recall\"] = [fmt(m, s) for m, s in zip(pretty.rec_mean, pretty.rec_std)]\n",
    "pretty[\"F1\"] = [fmt(m, s) for m, s in zip(pretty.f1_mean, pretty.f1_std)]\n",
    "pretty[\"ROC-AUC\"] = [fmt(m, s) for m, s in zip(pretty.auc_mean, pretty.auc_std)]\n",
    "\n",
    "pretty = pretty[[\"model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC-AUC\"]]\n",
    "pretty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43809a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ROC curves (OOF probabilities)\n",
    "plt.figure(figsize=(7, 6))\n",
    "for name, proba in oof_pred_proba.items():\n",
    "    valid = ~np.isnan(proba)\n",
    "    fpr, tpr, _ = roc_curve(y[valid], proba[valid])\n",
    "    auc = roc_auc_score(y[valid], proba[valid])\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"5-Fold OOF ROC Curves (All data mixed)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c00f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save results to CSV (optional)\n",
    "OUT_CSV = \"cv5_summary_unplanned_hospitalization.csv\"\n",
    "pretty.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved:\", OUT_CSV)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
